{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Ry2hyRlJkHJjx3ckWNCkoVWSrtT7vo2O","authorship_tag":"ABX9TyPR3w2WxJMbJTVcoUcCNWtO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"slh6XUauypF8","executionInfo":{"status":"ok","timestamp":1754545110683,"user_tz":-330,"elapsed":42,"user":{"displayName":"NANDIVADA PRASAD,ECE(2021) Vel Tech, Chennai","userId":"03851619064757488181"}}},"outputs":[],"source":[]},{"cell_type":"code","source":["# import header files\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import numpy as np"],"metadata":{"id":"eU1_1q8-0t03"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cGZ-NiC67SkE","executionInfo":{"status":"ok","timestamp":1729178609609,"user_tz":-330,"elapsed":24676,"user":{"displayName":"NANDIVADA PRASAD,ECE(2021) Vel Tech, Chennai","userId":"03851619064757488181"}},"outputId":"9d86bc2c-7c4f-47c1-f921-f9c722c8358f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["np.random.seed(1234)\n","torch.manual_seed(1234)\n","torch.cuda.manual_seed(1234)"],"metadata":{"id":"-PkqGy-D8JNy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define transforms\n","train_transforms = torchvision.transforms.Compose([torchvision.transforms.RandomRotation(30),\n","                                       torchvision.transforms.Resize((224, 224)),\n","                                       torchvision.transforms.RandomHorizontalFlip(),\n","                                       torchvision.transforms.ToTensor(),\n","                                       torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"],"metadata":{"id":"DWu1dtuH8OTM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip -uq \"/content/drive/MyDrive/minor/train.zip\" -d \"/content/drive/My Drive/PATH_TO_OUTPUT\""],"metadata":{"id":"QVqxhS6vFGCe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip -uq \"/content/drive/MyDrive/minor/val_images.zip\" -d \"/content/drive/My Drive/PATH_TO_OUTPUT\""],"metadata":{"id":"3CYs0Z3eS1uq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get data\n","train_data = torchvision.datasets.ImageFolder(\"/content/drive/MyDrive/PATH_TO_OUTPUT/train\", transform=train_transforms)\n","val_data = torchvision.datasets.ImageFolder(\"/content/drive/MyDrive/PATH_TO_OUTPUT/val_images\", transform=train_transforms)"],"metadata":{"id":"RGA1yOz_Q55A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data loader\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=16, pin_memory=True)\n","val_loader = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=True, num_workers=16, pin_memory=True)"],"metadata":{"id":"NBDUNRZRT_PL","executionInfo":{"status":"ok","timestamp":1729178808227,"user_tz":-330,"elapsed":0,"user":{"displayName":"NANDIVADA PRASAD,ECE(2021) Vel Tech, Chennai","userId":"03851619064757488181"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"927d4898-c827-415a-d982-eba1e49011b5"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["# define model\n","class ResNet_50(torch.nn.Module):\n","\n","\n","    # block 1\n","    def block_1_1(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(in_features, 64, kernel_size=1),\n","            torch.nn.BatchNorm2d(64),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_1_2(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(64),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_1_3(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(64, 256, kernel_size=1),\n","            torch.nn.BatchNorm2d(256)\n","        )\n","\n","    # block 2\n","    def block_2_init_1(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(in_features, 128, kernel_size=1, stride=2),\n","            torch.nn.BatchNorm2d(128),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_2_init_2(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(128),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_2_init_3(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(128, 512, kernel_size=1),\n","            torch.nn.BatchNorm2d(512)\n","        )\n","\n","    def block_2_1(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(in_features, 128, kernel_size=1),\n","            torch.nn.BatchNorm2d(128),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_2_2(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(128),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_2_3(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(128, 512, kernel_size=1),\n","            torch.nn.BatchNorm2d(512)\n","        )\n","\n","    # block 3\n","    def block_3_init_1(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(in_features, 256, kernel_size=1, stride=2),\n","            torch.nn.BatchNorm2d(256),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_3_init_2(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(256),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_3_init_3(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(256, 1024, kernel_size=1),\n","            torch.nn.BatchNorm2d(1024)\n","        )\n","\n","    def block_3_1(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(in_features, 256, kernel_size=1),\n","            torch.nn.BatchNorm2d(256),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_3_2(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(256),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_3_3(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(256, 1024, kernel_size=1),\n","            torch.nn.BatchNorm2d(1024)\n","        )\n","\n","    # block 4\n","    def block_4_init_1(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(in_features, 512, kernel_size=1, stride=2),\n","            torch.nn.BatchNorm2d(512),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_4_init_2(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(512),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_4_init_3(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(512, 2048, kernel_size=1),\n","            torch.nn.BatchNorm2d(2048)\n","        )\n","\n","    def block_4_1(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(in_features, 512, kernel_size=1),\n","            torch.nn.BatchNorm2d(512),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_4_2(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","            torch.nn.BatchNorm2d(512),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","    def block_4_3(self, in_features):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(512, 2048, kernel_size=1),\n","            torch.nn.BatchNorm2d(2048)\n","        )\n","\n","\n","    # init function\n","    def __init__(self, num_classes = 2):\n","        super(ResNet_50, self).__init__()\n","\n","        self.features = torch.nn.Sequential(\n","            torch.nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n","            torch.nn.BatchNorm2d(64),\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","        self.pool = torch.nn.Sequential(torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n","\n","        # spatial attention\n","        self.spatial_attention = torch.nn.Sequential(\n","            torch.nn.Conv2d(2, 1, kernel_size=7, padding=3, stride=1),\n","            torch.nn.BatchNorm2d(1),\n","            torch.nn.Sigmoid()\n","        )\n","\n","        # channel attention\n","        self.max_pool_11 = torch.nn.Sequential(torch.nn.MaxPool2d(kernel_size=112, stride=112))\n","        self.max_pool_1 = torch.nn.Sequential(torch.nn.MaxPool2d(kernel_size=56, stride=56))\n","        self.max_pool_2 = torch.nn.Sequential(torch.nn.MaxPool2d(kernel_size=28, stride=28))\n","        self.max_pool_3 = torch.nn.Sequential(torch.nn.MaxPool2d(kernel_size=14, stride=14))\n","        self.max_pool_4 = torch.nn.Sequential(torch.nn.MaxPool2d(kernel_size=7, stride=7))\n","        self.avg_pool_11 = torch.nn.Sequential(torch.nn.AvgPool2d(kernel_size=112, stride=112))\n","        self.avg_pool_1 = torch.nn.Sequential(torch.nn.AvgPool2d(kernel_size=56, stride=56))\n","        self.avg_pool_2 = torch.nn.Sequential(torch.nn.AvgPool2d(kernel_size=28, stride=28))\n","        self.avg_pool_3 = torch.nn.Sequential(torch.nn.AvgPool2d(kernel_size=14, stride=14))\n","        self.avg_pool_4 = torch.nn.Sequential(torch.nn.AvgPool2d(kernel_size=7, stride=7))\n","\n","        # block 1\n","        self.resnet_block_1_1_1 = self.block_1_1(64)\n","        self.resnet_block_1_1_2 = self.block_1_2(64)\n","        self.resnet_block_1_1_3 = self.block_1_3(64)\n","        self.resnet_block_1_2_1 = self.block_1_1(256)\n","        self.resnet_block_1_2_2 = self.block_1_2(256)\n","        self.resnet_block_1_2_3 = self.block_1_3(256)\n","        self.resnet_block_1_3_1 = self.block_1_1(256)\n","        self.resnet_block_1_3_2 = self.block_1_2(256)\n","        self.resnet_block_1_3_3 = self.block_1_3(256)\n","\n","        # block 2\n","        self.resnet_block_2_1_1 = self.block_2_init_1(256)\n","        self.resnet_block_2_1_2 = self.block_2_init_2(256)\n","        self.resnet_block_2_1_3 = self.block_2_init_3(256)\n","        self.resnet_block_2_2_1 = self.block_2_1(512)\n","        self.resnet_block_2_2_2 = self.block_2_2(512)\n","        self.resnet_block_2_2_3 = self.block_2_3(512)\n","        self.resnet_block_2_3_1 = self.block_2_1(512)\n","        self.resnet_block_2_3_2 = self.block_2_2(512)\n","        self.resnet_block_2_3_3 = self.block_2_3(512)\n","        self.resnet_block_2_4_1 = self.block_2_1(512)\n","        self.resnet_block_2_4_2 = self.block_2_2(512)\n","        self.resnet_block_2_4_3 = self.block_2_3(512)\n","\n","        # block 3\n","        self.resnet_block_3_1_1 = self.block_3_init_1(512)\n","        self.resnet_block_3_1_2 = self.block_3_init_2(512)\n","        self.resnet_block_3_1_3 = self.block_3_init_3(512)\n","        self.resnet_block_3_2_1 = self.block_3_1(1024)\n","        self.resnet_block_3_2_2 = self.block_3_2(1024)\n","        self.resnet_block_3_2_3 = self.block_3_3(1024)\n","        self.resnet_block_3_3_1 = self.block_3_1(1024)\n","        self.resnet_block_3_3_2 = self.block_3_2(1024)\n","        self.resnet_block_3_3_3 = self.block_3_3(1024)\n","        self.resnet_block_3_4_1 = self.block_3_1(1024)\n","        self.resnet_block_3_4_2 = self.block_3_2(1024)\n","        self.resnet_block_3_4_3 = self.block_3_3(1024)\n","        self.resnet_block_3_5_1 = self.block_3_1(1024)\n","        self.resnet_block_3_5_2 = self.block_3_2(1024)\n","        self.resnet_block_3_5_3 = self.block_3_3(1024)\n","        self.resnet_block_3_6_1 = self.block_3_1(1024)\n","        self.resnet_block_3_6_2 = self.block_3_2(1024)\n","        self.resnet_block_3_6_3 = self.block_3_3(1024)\n","\n","        # block 4\n","        self.resnet_block_4_1_1 = self.block_4_init_1(1024)\n","        self.resnet_block_4_1_2 = self.block_4_init_2(1024)\n","        self.resnet_block_4_1_3 = self.block_4_init_3(1024)\n","        self.resnet_block_4_2_1 = self.block_4_1(2048)\n","        self.resnet_block_4_2_2 = self.block_4_2(2048)\n","        self.resnet_block_4_2_3 = self.block_4_3(2048)\n","        self.resnet_block_4_3_1 = self.block_4_1(2048)\n","        self.resnet_block_4_3_2 = self.block_4_2(2048)\n","        self.resnet_block_4_3_3 = self.block_4_3(2048)\n","\n","        self.avgpool = torch.nn.AdaptiveAvgPool2d(7)\n","\n","        self.classifier = torch.nn.Sequential(\n","            torch.nn.Linear(2048 * 7 * 7, num_classes)\n","        )\n","\n","        self.relu = torch.nn.Sequential(\n","            torch.nn.ReLU(inplace=True)\n","        )\n","\n","        self.skip_connection_1 = torch.nn.Sequential(\n","            torch.nn.Conv2d(64, 256, kernel_size=1),\n","            torch.nn.BatchNorm2d(256)\n","        )\n","\n","        self.skip_connection_2 = torch.nn.Sequential(\n","            torch.nn.Conv2d(256, 512, kernel_size=1, stride=2),\n","            torch.nn.BatchNorm2d(512)\n","        )\n","\n","        self.skip_connection_3 = torch.nn.Sequential(\n","            torch.nn.Conv2d(512, 1024, kernel_size=1, stride=2),\n","            torch.nn.BatchNorm2d(1024)\n","        )\n","\n","        self.skip_connection_4 = torch.nn.Sequential(\n","            torch.nn.Conv2d(1024, 2048, kernel_size=1, stride=2),\n","            torch.nn.BatchNorm2d(2048)\n","        )\n","\n","\n","    # define forward function\n","    def forward(self, x):\n","\n","        # apply initial conv layers\n","        x = self.features(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_11(x) + self.avg_pool_11(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.pool(x)\n","\n","        # block 1\n","        input = x\n","        x = self.resnet_block_1_1_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_1(x) + self.avg_pool_1(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_1_1_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_1(x) + self.avg_pool_1(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_1_1_3(x)\n","        input = self.skip_connection_1(input)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_1(x) + self.avg_pool_1(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_1_2_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_1(x) + self.avg_pool_1(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_1_2_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_1(x) + self.avg_pool_1(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_1_2_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_1(x) + self.avg_pool_1(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_1_3_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_1(x) + self.avg_pool_1(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_1_3_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_1(x) + self.avg_pool_1(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_1_3_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_1(x) + self.avg_pool_1(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","\n","        # block 2\n","        input = x\n","        x = self.resnet_block_2_1_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_2_1_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_2_1_3(x)\n","        input = self.skip_connection_2(input)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_2_2_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_2_2_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_2_2_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_2_3_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_2_3_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_2_3_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_2_4_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_2_4_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_2_4_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_2(x) + self.avg_pool_2(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","\n","        # block 3\n","        input = x\n","        x = self.resnet_block_3_1_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_3_1_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_3_1_3(x)\n","        input = self.skip_connection_3(input)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_3_2_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_3_2_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_3_2_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_3_3_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_3_3_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_3_3_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_3_4_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_3_4_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_3_4_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_3_5_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_3_5_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_3_5_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_3_6_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_3_6_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_3_6_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_3(x) + self.avg_pool_3(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","\n","        # block 4\n","        input = x\n","        x = self.resnet_block_4_1_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_4(x) + self.avg_pool_4(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_4_1_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_4(x) + self.avg_pool_4(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_4_1_3(x)\n","        input = self.skip_connection_4(input)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_4(x) + self.avg_pool_4(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_4_2_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_4(x) + self.avg_pool_4(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_4_2_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_4(x) + self.avg_pool_4(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_4_2_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_4(x) + self.avg_pool_4(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        input = x\n","        x = self.resnet_block_4_3_1(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_4(x) + self.avg_pool_4(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x = self.resnet_block_4_3_2(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_4(x) + self.avg_pool_4(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","        x_1 = self.resnet_block_4_3_3(x)\n","        x = torch.add(input, x_1)\n","        x = self.relu(x)\n","        scale = torch.nn.functional.sigmoid(self.max_pool_4(x) + self.avg_pool_4(x)).expand_as(x)\n","        x = x * scale\n","        scale = torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n","        scale = self.spatial_attention(scale)\n","        x = x * scale\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.shape[0], -1)\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"OoSGKjVCUZ4c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ResNet_50()\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGR4GMgvUczS","executionInfo":{"status":"ok","timestamp":1729178808228,"user_tz":-330,"elapsed":0,"user":{"displayName":"NANDIVADA PRASAD,ECE(2021) Vel Tech, Chennai","userId":"03851619064757488181"}},"outputId":"46bcaffa-1c7c-40ca-a257-366d5580ade2"},"execution_count":null,"outputs":[{"data":{"text/plain":["ResNet_50(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (pool): Sequential(\n","    (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  )\n","  (spatial_attention): Sequential(\n","    (0): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n","    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): Sigmoid()\n","  )\n","  (max_pool_11): Sequential(\n","    (0): MaxPool2d(kernel_size=112, stride=112, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (max_pool_1): Sequential(\n","    (0): MaxPool2d(kernel_size=56, stride=56, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (max_pool_2): Sequential(\n","    (0): MaxPool2d(kernel_size=28, stride=28, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (max_pool_3): Sequential(\n","    (0): MaxPool2d(kernel_size=14, stride=14, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (max_pool_4): Sequential(\n","    (0): MaxPool2d(kernel_size=7, stride=7, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avg_pool_11): Sequential(\n","    (0): AvgPool2d(kernel_size=112, stride=112, padding=0)\n","  )\n","  (avg_pool_1): Sequential(\n","    (0): AvgPool2d(kernel_size=56, stride=56, padding=0)\n","  )\n","  (avg_pool_2): Sequential(\n","    (0): AvgPool2d(kernel_size=28, stride=28, padding=0)\n","  )\n","  (avg_pool_3): Sequential(\n","    (0): AvgPool2d(kernel_size=14, stride=14, padding=0)\n","  )\n","  (avg_pool_4): Sequential(\n","    (0): AvgPool2d(kernel_size=7, stride=7, padding=0)\n","  )\n","  (resnet_block_1_1_1): Sequential(\n","    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_1_1_2): Sequential(\n","    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_1_1_3): Sequential(\n","    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_1_2_1): Sequential(\n","    (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_1_2_2): Sequential(\n","    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_1_2_3): Sequential(\n","    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_1_3_1): Sequential(\n","    (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_1_3_2): Sequential(\n","    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_1_3_3): Sequential(\n","    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_2_1_1): Sequential(\n","    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_2_1_2): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_2_1_3): Sequential(\n","    (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_2_2_1): Sequential(\n","    (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_2_2_2): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_2_2_3): Sequential(\n","    (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_2_3_1): Sequential(\n","    (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_2_3_2): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_2_3_3): Sequential(\n","    (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_2_4_1): Sequential(\n","    (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_2_4_2): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_2_4_3): Sequential(\n","    (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_3_1_1): Sequential(\n","    (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_1_2): Sequential(\n","    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_1_3): Sequential(\n","    (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_3_2_1): Sequential(\n","    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_2_2): Sequential(\n","    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_2_3): Sequential(\n","    (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_3_3_1): Sequential(\n","    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_3_2): Sequential(\n","    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_3_3): Sequential(\n","    (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_3_4_1): Sequential(\n","    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_4_2): Sequential(\n","    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_4_3): Sequential(\n","    (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_3_5_1): Sequential(\n","    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_5_2): Sequential(\n","    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_5_3): Sequential(\n","    (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_3_6_1): Sequential(\n","    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_6_2): Sequential(\n","    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_3_6_3): Sequential(\n","    (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_4_1_1): Sequential(\n","    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_4_1_2): Sequential(\n","    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_4_1_3): Sequential(\n","    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_4_2_1): Sequential(\n","    (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_4_2_2): Sequential(\n","    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_4_2_3): Sequential(\n","    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (resnet_block_4_3_1): Sequential(\n","    (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_4_3_2): Sequential(\n","    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","  )\n","  (resnet_block_4_3_3): Sequential(\n","    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=7)\n","  (classifier): Sequential(\n","    (0): Linear(in_features=100352, out_features=2, bias=True)\n","  )\n","  (relu): Sequential(\n","    (0): ReLU(inplace=True)\n","  )\n","  (skip_connection_1): Sequential(\n","    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (skip_connection_2): Sequential(\n","    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (skip_connection_3): Sequential(\n","    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n","    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (skip_connection_4): Sequential(\n","    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n","    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":["# define optimizer\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.001)"],"metadata":{"id":"aWdRWcETUhnM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define loss for two-class problem\n","criterion = torch.nn.CrossEntropyLoss()"],"metadata":{"id":"d3UoeC2DUmxN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_losses = []\n","train_acc = []\n","val_losses = []\n","val_acc = []\n","best_metric = -1\n","best_metric_epoch = -1\n","\n","# train and validate\n","for epoch in range(0, 40):\n","\n","    # train\n","    model.train()\n","    training_loss = 0.0\n","    total = 0\n","    correct = 0\n","    for i, (input, target) in enumerate(train_loader):\n","\n","        input = input.to(device)\n","        target = target.to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        training_loss = training_loss + loss.item()\n","        _, predicted = output.max(1)\n","        total += target.size(0)\n","        correct += predicted.eq(target).sum().item()\n","\n","    training_loss = training_loss / float(len(train_loader))\n","    training_accuracy = str(100.0 * (float(correct) / float(total)))\n","    train_losses.append(training_loss)\n","    train_acc.append(training_accuracy)\n","\n","    # validate\n","    model.eval()\n","    valid_loss = 0.0\n","    total = 0\n","    correct = 0\n","    for i, (input, target) in enumerate(val_loader):\n","\n","        with torch.no_grad():\n","            input = input.to(device)\n","            target = target.to(device)\n","\n","            output = model(input)\n","            loss = criterion(output, target)\n","            _, predicted = output.max(1)\n","            total += target.size(0)\n","            correct += predicted.eq(target).sum().item()\n","\n","        valid_loss = valid_loss + loss.item()\n","    valid_loss = valid_loss / float(len(val_loader))\n","    valid_accuracy = str(100.0 * (float(correct) / float(total)))\n","    val_losses.append(valid_loss)\n","    val_acc.append(valid_accuracy)\n","\n","\n","    # store best model\n","    if(float(valid_accuracy) > best_metric and epoch >= 10):\n","      best_metric = float(valid_accuracy)\n","      best_metric_epoch = epoch\n","      torch.save(model.state_dict(), \"best_model.pth\")\n","\n","    print()\n","    print(\"Epoch\" + str(epoch) + \":\")\n","    print(\"Training Accuracy: \" + str(training_accuracy) + \"    Validation Accuracy: \" + str(valid_accuracy))\n","    print(\"Training Loss: \" + str(training_loss) + \"    Validation Loss: \" + str(valid_loss))\n","    print()"],"metadata":{"id":"IpS1kUcAUoRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","e = []\n","for index in range(0, 30):\n","    e.append(index)\n","\n","plt.plot(e, train_losses)\n","plt.show()"],"metadata":{"id":"rAlRIIMi8r7J"},"execution_count":null,"outputs":[]}]}